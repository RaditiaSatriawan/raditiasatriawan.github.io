<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Panduan Lengkap Penyiapan Kluster Statis Apache Spark & Hadoop Virtual Machine</title>
    <style>
        body {
            font-family: 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            margin: 0 auto;
            max-width: 900px;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
            border-bottom: 2px solid #fd7e14;
            padding-bottom: 10px;
        }
        h1 { font-size: 2.5em; text-align: center; }
        h2 { font-size: 2em; margin-top: 40px; }
        h3 { font-size: 1.5em; border-bottom: 1px dotted #ccc; }
        code {
            background-color: #ecf0f1;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Consolas', 'Courier New', monospace;
            font-size: 0.9em;
        }
        pre {
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        pre code {
            background-color: transparent;
            padding: 0;
        }
        .note {
            background-color: #e8f6fd;
            border-left: 5px solid #3498db;
            padding: 15px;
            margin: 20px 0;
        }
        .warning {
            background-color: #fdf3e8;
            border-left: 5px solid #e67e22;
            padding: 15px;
            margin: 20px 0;
        }
        .error-box {
            background-color: #fbeae5;
            border-left: 5px solid #e74c3c;
            padding: 1px 15px;
            margin: 20px 0;
        }
        .filename {
            color: #c0392b;
            font-weight: bold;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ccc;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #ecf0f1;
        }
    </style>
</head>
<body>

    <h1>Panduan Lengkap Penyiapan Kluster Statis Apache Spark & Hadoop Virtual Machine</h1>
    <p style="text-align: center;"><strong>Disusun pada:</strong> Sabtu, 16 Agustus 2025</p>

    <div class="note">
        Dokumen ini adalah panduan detail "dari nol" untuk membangun kluster komputasi 3-node (1 Master, 2 Slave) menggunakan arsitektur statis. Panduan ini didasarkan pada proses yang telah teruji dan menyertakan solusi untuk semua error umum yang ditemui selama proses penyiapan.
    </div>

    <h2>Daftar Isi</h2>
    <ol>
        <li><a href="#fase1">Fase 1: Persiapan VM Master (Template)</a></li>
        <li><a href="#fase2">Fase 2: Instalasi Perangkat Lunak Inti di Master</a></li>
        <li><a href="#fase3">Fase 3: Konfigurasi Terpusat di Master</a></li>
        <li><a href="#fase4">Fase 4: Kloning & Konfigurasi Node Slave</a></li>
        <li><a href="#fase5">Fase 5: Menghidupkan & Finalisasi Kluster</a></li>
        <li><a href="#fase6">Fase 6: Prosedur Operasional (Start/Stop)</a></li>
        <li><a href="#fase7">Fase 7: Menjalankan Benchmark & Troubleshooting Aplikasi</a></li>
    </ol>

    <h2 id="fase1">Fase 1: Persiapan VM Master (Template)</h2>
    <p>Node ini akan menjadi "cetakan" untuk seluruh kluster kita. Lakukan dengan benar.</p>
    
    <h3>1.1. Membuat Virtual Machine</h3>
    <ul>
        <li><b>Software:</b> VMware Workstation</li>
        <li><b>OS:</b> Ubuntu Desktop 24.04 LTS (atau 22.04 LTS)</li>
        <li><b>Konfigurasi VM:</b>
            <ul>
                <li><b>Memory:</b> 8 GB</li>
                <li><b>Processors:</b> 2 atau 4 core</li>
                <li><b>Hard Disk:</b> 40 GB, dengan opsi <b>"Store virtual disk as a single file"</b>.</li>
            </ul>
        </li>
    </ul>

    <h3>1.2. Instalasi Ubuntu</h3>
    <ol>
        <li>Saat instalasi, pilih <b>`Minimal installation`</b>.</li>
        <li>Di layar "Installation type", pilih `Erase disk and install Ubuntu`. Klik `Advanced features...` dan pastikan opsi <b>`Use LVM` TIDAK TERPILIH</b>.</li>
        <li>Selesaikan instalasi dan masuk ke desktop.</li>
    </ol>

    <h3>1.3. Konfigurasi Awal Sistem</h3>
    <p>Buka Terminal dan jalankan perintah berikut:</p>
    <pre><code># 1. Update semua paket
sudo apt update && sudo apt upgrade -y

# 2. Instal SSH Server (sangat penting untuk komunikasi kluster)
sudo apt install openssh-server -y</code></pre>

    <h3>1.4. Konfigurasi IP Statis</h3>
    <p>Edit file konfigurasi Netplan.</p>
    <pre><code>sudo nano /etc/netplan/01-network-manager-all.yaml</code></pre>
    <p>Hapus semua isinya dan ganti dengan ini (sesuaikan `gateway4` jika perlu):</p>
    <pre><code>network:
  version: 2
  renderer: NetworkManager
  ethernets:
    ens33: # Nama antarmuka Anda mungkin berbeda, cek dengan `ip a`
      dhcp4: no
      addresses: [192.168.100.10/24] # IP untuk Master
      gateway4: 192.168.100.2
      nameservers:
        addresses: [8.8.8.8, 8.8.4.4]</code></pre>
    <p>Terapkan perubahan dan reboot:</p>
    <pre><code>sudo netplan apply
sudo reboot</code></pre>
    
    <h2 id="fase2">Fase 2: Instalasi Perangkat Lunak Inti di Master</h2>
    
    <h3>2.1. Instalasi Java</h3>
    <pre><code>sudo add-apt-repository ppa:linuxuprising/java -y
sudo apt update
sudo apt install openjdk-8-jdk-headless -y
java -version</code></pre>

    <h3>2.2. Instalasi Apache Spark</h3>
    <pre><code>cd ~
wget https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz
tar xvf spark-3.5.1-bin-hadoop3.tgz
sudo mv spark-3.5.1-bin-hadoop3 /opt/spark</code></pre>

    <h3>2.3. Instalasi Apache Hadoop</h3>
    <pre><code>cd ~
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar xvf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /opt/hadoop</code></pre>

    <h3>2.4. Instalasi Pustaka Python</h3>
    <p>Sangat penting untuk benchmark machine learning nanti.</p>
    <pre><code>sudo apt install python3-numpy python3-pandas -y</code></pre>

    <h2 id="fase3">Fase 3: Konfigurasi Terpusat di Master</h2>
    
    <h3>3.1. Penyiapan Variabel Lingkungan</h3>
    <p>Buka file <code class="filename">~/.bashrc</code>:</p>
    <pre><code>nano ~/.bashrc</code></pre>
    <p>Tambahkan semua baris berikut di bagian paling bawah file:</p>
    <pre><code># SPARK & HADOOP ENV VARIABLES
export SPARK_HOME=/opt/spark
export HADOOP_HOME=/opt/hadoop
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export PATH=$PATH:$SPARK_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></pre>
    <p>Simpan file, lalu muat ulang konfigurasi: <code>source ~/.bashrc</code></p>

    <h3>3.2. Konfigurasi File Inti Hadoop</h3>
    <p>Buat direktori data Hadoop:</p>
    <pre><code>sudo mkdir -p /opt/hadoop-data/nameNode
sudo mkdir -p /opt/hadoop-data/dataNode
sudo chown $(whoami):$(whoami) -R /opt/hadoop-data</code></pre>
    <p>Kemudian, edit file-file XML di <code class="filename">/opt/hadoop/etc/hadoop/</code>.</p>
    <ul>
        <li><b><code class="filename">hadoop-env.sh</code>:</b> Pastikan baris ini ada: <code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</code></li>
        <li><b><code class="filename">core-site.xml</code>:</b>
            <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://master:8020&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
        </li>
        <li><b><code class="filename">hdfs-site.xml</code>:</b>
            <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;/opt/hadoop-data/nameNode&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;/opt/hadoop-data/dataNode&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
        </li>
        <li><b><code class="filename">yarn-site.xml</code>:</b> (Nilai memori disesuaikan untuk VM 8GB)
            <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;master&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;6144&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
        </li>
        <li><b><code class="filename">workers</code>:</b> Hapus <code>localhost</code> dan isi dengan:
            <pre><code>slave01
slave02</code></pre>
        </li>
    </ul>

    <h3>3.3. Konfigurasi File Inti Spark</h3>
    <p>Edit file-file di <code class="filename">/opt/spark/conf/</code>.</p>
     <ul>
        <li><b><code class="filename">spark-env.sh</code>:</b> Buat file ini jika belum ada, lalu tambahkan:
            <pre><code>export SPARK_MASTER_HOST=master</code></pre>
        </li>
        <li><b><code class="filename">workers</code>:</b> Pastikan isinya sama dengan file workers Hadoop:
            <pre><code>slave01
slave02</code></pre>
        </li>
    </ul>
    
    <h2 id="fase4">Fase 4: Kloning & Konfigurasi Node Slave</h2>
    <ol>
        <li><b>Matikan</b> VM `master` sepenuhnya.</li>
        <li>Di VMware, klik kanan `master` > `Manage` > `Clone...`.</li>
        <li>Pilih <b>`Create a full clone`</b>. Beri nama `slave01`.</li>
        <li>Ulangi proses untuk membuat `slave02`.</li>
        <li>Untuk setiap slave, nyalakan **satu per satu** dan lakukan:
            <ul>
                <li>Ubah <b>hostname</b> (misal: <code>sudo hostnamectl set-hostname slave01</code>).</li>
                <li>Ubah <b>alamat IP statis</b> di file Netplan (<code>192.168.100.11</code> untuk slave01, <code>192.168.100.12</code> untuk slave02).</li>
                <li><b>SANGAT PENTING:</b> Pastikan file <code class="filename">/etc/hosts</code> di **SEMUA** node (master dan semua slave) berisi peta lengkap kluster:
                    <pre><code>127.0.0.1       localhost
192.168.100.10  master
192.168.100.11  slave01
192.168.100.12  slave02</code></pre>
                </li>
            </ul>
        </li>
    </ol>

    <h2 id="fase5">Fase 5: Menghidupkan & Finalisasi Kluster</h2>
    <p>Nyalakan semua VM. Semua perintah berikut dijalankan dari terminal <b>master</b>.</p>

    <h3>5.1. Penyiapan SSH Tanpa Password</h3>
    <pre><code># Buat kunci jika belum ada
ssh-keygen -t rsa

# Salin kunci ke semua node
ssh-copy-id master
ssh-copy-id slave01
ssh-copy-id slave02</code></pre>
    <div class="error-box">
        <h4>Troubleshooting SSH</h4>
        <p><b>Error:</b> <code>Connection refused</code><br><b>Solusi:</b> Server SSH tidak berjalan di node tujuan. Di node tujuan, jalankan <code>sudo systemctl start ssh</code>.</p>
        <p><b>Error:</b> <code>Could not resolve hostname</code><br><b>Solusi:</b> File <code class="filename">/etc/hosts</code> di mesin Anda (master) salah. Periksa kembali isinya.</p>
    </div>

    <h3>5.2. Format HDFS NameNode (Tindakan Satu Kali)</h3>
    <div class="warning">Jalankan perintah ini <b>HANYA SEKALI</b> saat pertama kali membuat kluster. Jangan pernah menjalankannya lagi atau data Anda akan hilang.</div>
    <pre><code>hdfs namenode -format</code></pre>
    <div class="error-box">
        <h4>Troubleshooting HDFS</h4>
        <p><b>Error:</b> <code>hdfs: command not found</code><br><b>Solusi:</b> Konfigurasi `PATH` belum dimuat. Jalankan <code>source ~/.bashrc</code> di terminal Anda, lalu coba lagi.</p>
        <p><b>Error:</b> <code>ERROR: JAVA_HOME is not set</code><br><b>Solusi:</b> File <code class="filename">/opt/hadoop/etc/hadoop/hadoop-env.sh</code> salah atau belum disalin ke slave. Perbaiki file di master, lalu salin ke semua slave dengan <code>scp</code>.</p>
    </div>

    <h2 id="fase6">Fase 6: Prosedur Operasional (Start/Stop)</h2>
    
    <h3>6.1. Prosedur Startup yang Andal</h3>
    <p>Dari terminal <b>master</b>, jalankan secara berurutan:</p>
    <pre><code># 1. Mulai HDFS
/opt/hadoop/sbin/start-dfs.sh

# 2. Mulai YARN
/opt/hadoop/sbin/start-yarn.sh

# 3. Mulai Spark
/opt/spark/sbin/start-all.sh</code></pre>

    <h3>6.2. Verifikasi</h3>
    <ul>
        <li><b>Di `master`</b>, jalankan <code>jps</code>. Harus ada: `NameNode`, `ResourceManager`, `Master`, `SecondaryNameNode`.</li>
        <li><b>Di `slave`</b> (via <code>ssh slave01</code>), jalankan <code>jps</code>. Harus ada: `DataNode`, `NodeManager`, `Worker`.</li>
        <li>Buka browser di `master` dan kunjungi <code>http://master:8080</code> untuk melihat Spark UI. Pastikan kedua slave terdaftar sebagai worker.</li>
    </ul>
    <div class="error-box">
        <h4>Troubleshooting Startup</h4>
        <p><b>Problem:</b> Worker Spark tidak muncul di UI.<br><b>Solusi:</b> Ini masalah paling umum. Periksa 3 hal: <b>1)</b> File <code class="filename">/opt/spark/conf/workers</code> di master sudah benar. <b>2)</b> File <code class="filename">/etc/hosts</code> di **semua slave** sudah benar dan berisi alamat IP `master`. <b>3)</b> File <code class="filename">/opt/spark/conf/spark-env.sh</code> di **semua node** berisi <code>export SPARK_MASTER_HOST=master</code> (salin dari master ke slave jika perlu).</p>
    </div>

    <h3>6.3. Prosedur Shutdown yang Aman</h3>
    <p>Dari terminal <b>master</b>, jalankan secara berurutan:</p>
    <pre><code>/opt/spark/sbin/stop-all.sh
/opt/hadoop/sbin/stop-yarn.sh
/opt/hadoop/sbin/stop-dfs.sh</code></pre>
    <p>Setelah itu, Anda bisa mematikan setiap VM dengan <code>sudo shutdown now</code>.</p>

    <h2 id="fase7">Fase 7: Menjalankan Benchmark & Troubleshooting Aplikasi</h2>
    <p>Ini adalah fase di mana Anda menjalankan kode Anda, seperti skrip benchmark.</p>
    <div class="error-box">
        <h4>Troubleshooting Kode Spark</h4>
        <p><b>Error:</b> <code>ModuleNotFoundError: No module named 'numpy'</code><br><b>Solusi:</b> Pustaka Python belum diinstal di semua node. Jalankan <code>sudo apt install python3-numpy python3-pandas -y</code> di **semua node** (master dan semua slave).</p>
        <p><b>Error:</b> <code>Connection refused</code> saat menjalankan job<br><b>Solusi:</b> Anda sedang menjalankan tes single-node tetapi skrip Anda mencoba membaca dari HDFS (`hdfs://...`). Edit skrip untuk membaca dari file lokal (`file:///...`) untuk tes ini.</p>
        <p><b>Error:</b> <code>Parquet column cannot be converted</code> atau <code>ClassCastException</code><br><b>Solusi:</b> Ini adalah masalah tipe data yang rumit. Solusi paling kuat adalah dengan menonaktifkan pembaca parquet yang ketat DAN secara eksplisit mengubah tipe data kolom di dalam kode Spark Anda, seperti yang telah kita lakukan pada skrip benchmark.</p>
    </div>

</body>
</html>